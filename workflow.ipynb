{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.coordinates import EarthLocation, AltAz, SkyCoord\n",
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "from utils import Leg_poly_proj, view_samples\n",
    "from flicker_model import sim_noise, flicker_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates:\n",
    "- MeerKAT Telescope Location:\n",
    "\t-\tLatitude: -30.7130째 S\n",
    "\t-\tLongitude: 21.4430째 E\n",
    "\n",
    "- Antenna pointing directions:\n",
    "\t-\tAzimuth\n",
    "\t-\tElevation\n",
    "\n",
    "- Diffuse sky coordinates:\n",
    "\t-\tRA \n",
    "\t-\tDEC\n",
    "\n",
    "- healpy expects (theta, phi) in spherical coordinates:\n",
    "\t-\ttheta = pi/2 - DEC\n",
    "\t-\tphi = RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antenna position: Latitude: -30.7130째 S; Longitude: 21.4430째 E.\n",
    "\n",
    "# ---- Define telescope location ----\n",
    "telescope_lat = -30.7130  # MeerKAT latitude in degrees\n",
    "telescope_lon = 21.4430   # MeerKAT longitude in degrees\n",
    "telescope_height = 1054    # MeerKAT altitude in meters\n",
    "\n",
    "location = EarthLocation(lat=telescope_lat * u.deg, lon=telescope_lon * u.deg, height=telescope_height * u.m)\n",
    "\n",
    "\n",
    "# ---- Define observation parameters ----\n",
    "\n",
    "# Antenna pointings: Azimuth list and Elevation, in degrees\n",
    "# aux = np.linspace(-60, -40, 111)\n",
    "aux = np.linspace(-65, -35, 171)\n",
    "azimuths = np.concatenate((aux[1:-1][::-1], aux))\n",
    "#azimuths = np.concatenate((aux, aux[1:-1][::-1]))\n",
    "\n",
    "# Generate 13 repeats of the azimuths\n",
    "azimuths = np.tile(azimuths, 25)\n",
    "\n",
    "\n",
    "elevation = 41.7    # Elevation in degrees\n",
    "\n",
    "elevation = 60    # Elevation in degrees\n",
    "\n",
    "# Total length of TOD\n",
    "ntime = len(azimuths)\n",
    "print(\"Total length of TOD: \", ntime)\n",
    "dtime = 2.0\n",
    "\n",
    "t_list = np.arange(ntime) * dtime \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "# Generate the equatorial coordinates of the pointings:\n",
    "ra_list = []\n",
    "dec_list = []\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(t_list, azimuths)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Azimuth (deg)')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t_list, elevation*np.ones_like(azimuths))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Elevation (deg)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define start and end times in SAST ----\n",
    "start_time_sast = \"2024-02-23 19:54:07.397\"\n",
    "#end_time_sast = \"2024-02-23 22:12:04.632\"\n",
    "\n",
    "# ---- Convert to UTC (SAST = UTC+2) ----\n",
    "start_time = Time(start_time_sast) - TimeDelta(2 * u.hour)\n",
    "#end_time = Time(end_time_sast) - TimeDelta(2 * u.hour)\n",
    "\n",
    "# ---- Generate time list using numpy.arange ----\n",
    "dt = 2  # Time step in seconds\n",
    "time_list = start_time + TimeDelta(t_list, format='sec')\n",
    "\n",
    "# ---- Print results ----\n",
    "print(f\"Generated {len(time_list)} timestamps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create AltAz coordinate frame ----\n",
    "altaz_frame = AltAz(obstime=time_list, location=location)\n",
    "\n",
    "# ---- Convert Az/El to Equatorial (RA, Dec) ----\n",
    "equatorial_coords = SkyCoord(az=azimuths*u.deg, alt=elevation*u.deg, frame=altaz_frame).transform_to(\"icrs\")\n",
    "\n",
    "\n",
    "# Convert the equatorial coordinates to pixel indices\n",
    "# Note: healpy expects (theta, phi) in spherical coordinates\n",
    "theta_c = np.pi/2 - equatorial_coords.dec.radian  # Convert Dec to theta\n",
    "phi_c = equatorial_coords.ra.radian               # RA is already phi\n",
    "\n",
    "# ---- Plot results ----\n",
    "# Generate a 2D plot of (RA, Dec) coordinates\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(equatorial_coords.ra, equatorial_coords.dec)\n",
    "plt.xlabel(\"Right Ascension (degrees)\")\n",
    "plt.ylabel(\"Declination (degrees)\")\n",
    "plt.title(\"Sky Coordinates at Different Times\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam setup\n",
    "\n",
    " Gaussian Beam (FWHM = 1.1 degrees)\n",
    "\n",
    "$\n",
    "\\text{FWHM} = 2 \\sigma \\sqrt{2 \\ln(2)}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define beam parameters\n",
    "FWHM = 1.1  # Full Width at Half Maximum in degrees\n",
    "sigma = FWHM / (2 * np.sqrt(2 * np.log(2)))  # Convert FWHM to sigma (degrees)\n",
    "sigma_rad = np.radians(sigma)  # Convert to radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_angular_size(nside):\n",
    "    \"\"\"Compute the angular size (in degrees and arcminutes) of a HEALPix pixel.\"\"\"\n",
    "    npix = hp.nside2npix(nside)  # Total number of pixels\n",
    "    omega_pix = 4 * np.pi / npix  # Pixel area in steradians\n",
    "    theta_pix_deg = np.sqrt(omega_pix) * (180 / np.pi)  # Approximate pixel width in degrees\n",
    "    theta_pix_arcmin = theta_pix_deg * 60  # Convert to arcminutes\n",
    "    return theta_pix_deg, theta_pix_arcmin\n",
    "\n",
    "# Example usage\n",
    "nside = 64 # Change NSIDE as needed\n",
    "theta_deg, theta_arcmin = pixel_angular_size(nside)\n",
    "print(f\"NSIDE = {nside}\")\n",
    "print(f\"Pixel angular size: {theta_deg:.6f} degrees ({theta_arcmin:.2f} arcminutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HEALPix resolution\n",
    "NSIDE = 64\n",
    "NPIX = hp.nside2npix(NSIDE)  \n",
    "\n",
    "# Get HEALPix pixel coordinates (theta, phi)\n",
    "theta, phi = hp.pix2ang(NSIDE, np.arange(NPIX))\n",
    "\n",
    "# Generate a initial boolean map with all pixels zero\n",
    "bool_map = np.zeros(NPIX, dtype=bool)\n",
    "sum_map = np.zeros(NPIX, dtype=float)\n",
    "# ---- Set the threshold ----\n",
    "threshold = 1e-1  # Example: Get all pixels where the value is > 0.5\n",
    "\n",
    "for ti in range(ntime):\n",
    "    # Compute angular separation between each pixel and the beam center\n",
    "    cos_sep = np.cos(theta) * np.cos(theta_c[ti]) + np.sin(theta) * np.sin(theta_c[ti]) * np.cos(phi - phi_c[ti])\n",
    "    cos_sep = np.clip(cos_sep, -1, 1)  # Ensure within valid range\n",
    "    angular_sep = np.arccos(cos_sep)  # Separation in radians\n",
    "    # Compute Gaussian beam response centered at (RA_center, Dec_center)\n",
    "    beam_map = np.exp(-0.5 * (angular_sep / sigma_rad) ** 2)\n",
    "    # Normalize the beam (optional, ensures peak = 1)\n",
    "    beam_map /= np.max(beam_map)\n",
    "    sum_map += beam_map\n",
    "    # Get the \"or\" map of the bool_map and beam_map\n",
    "    bool_map = np.logical_or(bool_map, beam_map > threshold)\n",
    "\n",
    "# Count the number of \"1\" pixels in bool_map\n",
    "num_pixels = np.sum(bool_map)\n",
    "print(f\"Number of covered pixels: {num_pixels}\")\n",
    "\n",
    "# Get the pixel indices of the \"1\" pixels:\n",
    "pixel_indices = np.where(bool_map)[0]\n",
    "\n",
    "# Save HEALPix map to file\n",
    "#hp.write_map(\"gaussian_beam_pointing.fits\", beam_map, overwrite=True)\n",
    "\n",
    "# Plot the beam in Mollweide projection\n",
    "hp.mollview(sum_map, title=f\"Sumed Gaussian Beam\", unit=\"Arbitrary Units\")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(bool_map, title=f\"Boolean map: masked pixels\", unit=\"Arbitrary Units\")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixels of skymap where corresponding mask value (bool_map) is true \n",
    "\n",
    "beam_proj = np.zeros((ntime, num_pixels))\n",
    "\n",
    "for ti in range(ntime):\n",
    "    # Compute angular separation between each pixel and the beam center\n",
    "    cos_sep = np.cos(theta) * np.cos(theta_c[ti]) + np.sin(theta) * np.sin(theta_c[ti]) * np.cos(phi - phi_c[ti])\n",
    "    cos_sep = np.clip(cos_sep, -1, 1)  # Ensure within valid range\n",
    "    angular_sep = np.arccos(cos_sep)  # Separation in radians\n",
    "    # Compute Gaussian beam response centered at (RA_center, Dec_center)\n",
    "    beam_map = np.exp(-0.5 * (angular_sep / sigma_rad) ** 2)\n",
    "    # Normalize the beam (optional, ensures peak = 1)\n",
    "    beam_map /= np.max(beam_map)\n",
    "    beam_proj[ti] = beam_map[pixel_indices]\n",
    "\n",
    "norm=np.sum(beam_proj, axis=1)\n",
    "beam_proj/=norm[:,None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sky temperature simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygdsm import GlobalSkyModel\n",
    "gsm = GlobalSkyModel()\n",
    "gsm.nside =NSIDE\n",
    "skymap = gsm.generate(500)\n",
    "true_Tsky = skymap[pixel_indices]\n",
    "gsm.view(logged=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise diode setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a vector of length ntime, every 10 elements there is a 1, the rest is 0\n",
    "def generate_vector(ntime):\n",
    "    vector = np.zeros(ntime)\n",
    "    for i in range(0, ntime, 10):\n",
    "        vector[i] = 1\n",
    "    return vector\n",
    "\n",
    "ndiode_proj = generate_vector(ntime)\n",
    "\n",
    "T_ndiode = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_proj = Leg_poly_proj(4, t_list)[:, 1:]\n",
    "rec_params=np.array([4, 0.5, 1])\n",
    "plt.title(\"Receiver temperature\")\n",
    "plt.plot(rec_proj @ rec_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain and noise setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample list of 3D arrays with the same shape for axes 1 and 2, but different sizes for axis 0\n",
    "array1 = np.random.random((3, 4, 5))  # Shape (3, 4, 5)\n",
    "array2 = np.random.random((2, 4, 5))  # Shape (2, 4, 5)\n",
    "array3 = np.random.random((4, 4, 5))  # Shape (4, 4, 5)\n",
    "\n",
    "# List of arrays\n",
    "arrays = [array1, array2, array3]\n",
    "\n",
    "# Stack along axis 0 (concatenate along the first dimension)\n",
    "stacked_array = np.concatenate(arrays, axis=0)\n",
    "\n",
    "# Check the result shape\n",
    "print(stacked_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import cholesky\n",
    "\n",
    "gain_proj = Leg_poly_proj(4, t_list)\n",
    "gain_params=np.array([2, 0.5, 1.5, 0.5])*2\n",
    "# mu0 = np.sin(2*np.pi*0.001*t_list)\n",
    "mu0 = 0.\n",
    "gains = gain_proj @ gain_params + mu0\n",
    "\n",
    "f0, fc, alpha = 1e-4, 2e-5, 2.0\n",
    "sigma_2 = 1/(4e5)\n",
    "\n",
    "noise = sim_noise(f0, fc, alpha, t_list, n_samples=1, white_n_variance=sigma_2)[0]\n",
    "covmat = flicker_cov(t_list, f0, fc, alpha, white_n_variance=sigma_2, only_row_0=False)\n",
    "# invert the symmetric matrix, covmat\n",
    "Ninv = np.linalg.inv(covmat)\n",
    "\n",
    "aux_mat = cholesky(Ninv, upper=True)\n",
    "white_noise = aux_mat @ noise\n",
    "\n",
    "# Check if white noise is white: compare PSD of corr_noise and white_noise\n",
    "psd_corr = np.abs(np.fft.rfft(noise))**2\n",
    "psd_white = np.abs(np.fft.rfft(white_noise))**2\n",
    "freqs = np.fft.rfftfreq(ntime, d=2)\n",
    "# plot psd\n",
    "plt.loglog(freqs, psd_corr, label='corr_noise')\n",
    "plt.loglog(freqs, psd_white, label='white_noise')\n",
    "ex_noise = np.random.randn(ntime)\n",
    "psd_ex = np.abs(np.fft.rfft(ex_noise))**2\n",
    "plt.loglog(freqs, psd_ex, label='ex_noise')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_gains = 1/gains\n",
    "p_gain_var = gain_proj.T @ (inv_gains[:, np.newaxis] * Ninv * inv_gains[np.newaxis, :]) @ gain_proj\n",
    "p_gain_var = np.diag(np.linalg.inv(p_gain_var))\n",
    "p_gain_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tsys_sampler import Tsys_model\n",
    "\n",
    "TOD_ndiode = T_ndiode*ndiode_proj\n",
    "TOD_rec = rec_proj @ rec_params\n",
    "Tsys_sim = Tsys_model([beam_proj, rec_proj, ndiode_proj], [true_Tsky, rec_params, T_ndiode])\n",
    "TOD_sim = Tsys_sim * (1+noise) * gains \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a sequence of time-ordered data for a scan of a receiver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Parameter Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise_sampler import noise_params_sampler, flicker_likeli_func\n",
    "from mcmc_sampler import mcmc_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logn_params = [np.log10(f0), np.log10(fc), alpha]\n",
    "# boundaries = [[-12.,0.], [-12.,0.], [1.01,5.0]]\n",
    "# log_likeli = flicker_likeli_func(t_list, TOD_sim, gains, Tsys_sim, wnoise_var=2.5e-6, boundaries=None)\n",
    "# noise_samples_Jeff = mcmc_sampler(log_likeli, logn_params, p_std=0.05, \n",
    "#                     nsteps=50,  # steps for each chain\n",
    "#                     n_samples=1,\n",
    "#                     prior_func=None,\n",
    "#                     num_Jeffrey=False,\n",
    "#                     return_sampler=False)\n",
    "\n",
    "# view_samples(noise_samples_Jeff, logn_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_samples_no_prior = noise_params_sampler(t_list, TOD_sim, gains, Tsys_sim, \n",
    "#                         sigma_2,\n",
    "#                         nwalkers=6, \n",
    "#                         nsteps=100, \n",
    "#                         n_samples=300,\n",
    "#                         log_scale=True, \n",
    "#                         prior_func=None,\n",
    "#                         return_sampler=False)\n",
    "\n",
    "# noise_samples = noise_samples_no_prior\n",
    "# # Calculate statistics\n",
    "# mean = np.mean(noise_samples, axis=0)\n",
    "# std = np.std(noise_samples, axis=0)\n",
    "\n",
    "# # Create subplots for four parameters\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# logn_params = np.log10(f0), np.log10(fc), alpha\n",
    "# params_names = ['log(f0)', 'log(fc)', 'alpha']\n",
    "# for i in range(3):\n",
    "#     # Plot histogram of samples for each parameter\n",
    "#     axes[i].hist(noise_samples[:, i], bins=50, density=True, alpha=0.6, label='Samples')\n",
    "    \n",
    "#     # Plot true value line\n",
    "#     axes[i].axvline(x=logn_params[i], color='r', linestyle='-', label='True Value', linewidth=2, alpha=0.7)\n",
    "    \n",
    "#     # Plot mean value line\n",
    "#     axes[i].axvline(x=mean[i], color='g', linestyle='--', label='Mean')\n",
    "    \n",
    "#     # Add labels and title\n",
    "#     axes[i].set_xlabel('Coefficient')\n",
    "#     axes[i].set_ylabel('Density')\n",
    "#     axes[i].set_title(f'Parameter {params_names[i]}')\n",
    "#     axes[i].legend()\n",
    "    \n",
    "#     # Print numerical comparison for each parameter\n",
    "#     print(f\"\\nGain Parameter {i+1}:\")\n",
    "#     print(f\"True value: {logn_params[i]:.6f}\")\n",
    "#     print(f\"Mean sampled: {mean[i]:.6f}\")\n",
    "#     print(f\"Standard deviation: {std[i]:.6f}\")\n",
    "\n",
    "# plt.suptitle('Comparison of True Values, Mean for Noise Parameters (No Prior) (300 samples)')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain Sampler Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the gain sampler, we sample gain coefficients with given noise parameters and system parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Generalised Least Squares (GLS) procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gain_sampler import gain_coeff_sampler\n",
    "\n",
    "gain_samples = gain_coeff_sampler(TOD_sim, \n",
    "                    gain_proj, \n",
    "                    Tsys_sim, \n",
    "                    covmat, \n",
    "                    mu=mu0,\n",
    "                    n_samples=4000,\n",
    "                    tol=1e-20,\n",
    "                    prior_cov_inv=None, \n",
    "                    prior_mean=None, \n",
    "                    solver=None)\n",
    "\n",
    "view_samples(gain_samples, gain_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_gains = 1/gains\n",
    "p_gain_var = gain_proj.T @ (inv_gains[:, np.newaxis] * Ninv * inv_gains[np.newaxis, :]) @ gain_proj\n",
    "p_gain_var = np.diag(np.linalg.inv(p_gain_var))\n",
    "np.sqrt(p_gain_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System temperature sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tsys_sampler import Tsys_coeff_sampler, overall_operator\n",
    "\n",
    "TOD_ndiode = T_ndiode*ndiode_proj\n",
    "\n",
    "Tsys_proj = overall_operator([beam_proj, rec_proj])\n",
    "\n",
    "\n",
    "Tsys_params = Tsys_coeff_sampler(TOD_sim, \n",
    "                       gains, \n",
    "                       Tsys_proj, \n",
    "                       covmat, \n",
    "                       n_samples=100,\n",
    "                       mu=TOD_ndiode,\n",
    "                       tol=1e-17,\n",
    "                       prior_cov_inv=None, \n",
    "                       prior_mean=None, \n",
    "                       solver=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsky_samples = Tsys_params[:,:num_pixels]\n",
    "Tsky_mean = np.mean(Tsky_samples, axis=0)\n",
    "Tsky_std = np.std(Tsky_samples, axis=0)\n",
    "#Trec_samples = Tsys_params[:,num_pixels:]\n",
    "#view_samples(Trec_samples, rec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true Tsky and sampled Tsky\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_Tsky, label='True Tsky')\n",
    "# Plot the mean of the samples, with error bars being the standard deviation\n",
    "plt.errorbar(np.arange(len(true_Tsky)), Tsky_mean, yerr=Tsky_std, label='Sampled Tsky')\n",
    "plt.ylim(5, 12)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_Tsky, label='True Tsky')\n",
    "# Plot the mean of the samples, with error bars being the standard deviation\n",
    "plt.plot(Tsky_mean, label='Mean of samples')\n",
    "plt.ylim(5, 12)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Tsky_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the full Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from full_Gibbs_sampler import full_Gibbs_sampler_singledish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read off the samples from Tsys_samples.npy\n",
    "#\n",
    "\n",
    "Tsys_samples = np.load('Tsys_samples.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsky_samples = Tsys_samples[:, :num_pixels]\n",
    "Tmean = np.mean(Tsky_samples, axis=0)\n",
    "Tstd = np.std(Tsky_samples, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# plot the mean with error bars\n",
    "# plt.errorbar(range(len(Tmean)), Tmean, yerr=Tstd, fmt='o', label='mean Tsky')\n",
    "plt.plot(range(len(Tmean)), Tmean, label='mean Tsky')\n",
    "plt.plot(range(len(Tmean)), true_Tsky, label='true Tsky', linestyle='--')\n",
    "plt.ylim(5, 15)\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the healpix maps\n",
    "\n",
    "true_map = np.zeros(NPIX, dtype=float)\n",
    "sample_mean_map = np.zeros(NPIX, dtype=float)\n",
    "sample_std_map = np.zeros(NPIX, dtype=float)\n",
    "\n",
    "true_map[pixel_indices] = true_Tsky\n",
    "sample_mean_map[pixel_indices] = Tmean\n",
    "sample_std_map[pixel_indices] = Tstd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the map using the saved colorbar\n",
    "\n",
    "hp.mollview(true_map, title=\"True Tsky\", unit=\"K\", cmap='jet', min=5, max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(sample_mean_map, title=\"Mean Sampled Tsky\", unit=\"K\", cmap='jet', min=5, max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
